{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e91cdb-4693-4632-b7aa-f37eec027131",
   "metadata": {},
   "source": [
    "## Working with Transformers in the HuggingFace Ecosystem\n",
    "\n",
    "In this laboratory exercise we will learn how to work with the HuggingFace ecosystem to adapt models to new tasks. As you will see, much of what is required is *investigation* into the inner-workings of the HuggingFace abstractions. With a little work, a little trial-and-error, it is fairly easy to get a working adaptation pipeline up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e556105-269f-43e3-8933-227269afb9ea",
   "metadata": {},
   "source": [
    "### Exercise 1: Sentiment Analysis (warm up)\n",
    "\n",
    "In this first exercise we will start from a pre-trained BERT transformer and build up a model able to perform text sentiment analysis. Transformers are complex beasts, so we will build up our pipeline in several explorative and incremental steps.\n",
    "\n",
    "#### Exercise 1.1: Dataset Splits and Pre-trained model\n",
    "There are a many sentiment analysis datasets, but we will use one of the smallest ones available: the [Cornell Rotten Tomatoes movie review dataset](cornell-movie-review-data/rotten_tomatoes), which consists of 5,331 positive and 5,331 negative processed sentences from the Rotten Tomatoes movie reviews.\n",
    "\n",
    "**Your first task**: Load the dataset and figure out what splits are available and how to get them. Spend some time exploring the dataset to see how it is organized. Note that we will be using the [HuggingFace Datasets](https://huggingface.co/docs/datasets/en/index) library for downloading, accessing, splitting, and batching data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15819af4-e850-412b-ab67-61b9b98e3a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eledaveri/miniconda3/envs/labs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'train' contains 8530 examples\n",
      "Split 'validation' contains 1066 examples\n",
      "Split 'test' contains 1066 examples\n",
      "\n",
      "Data structure:\n",
      "{'text': Value('string'), 'label': ClassLabel(names=['neg', 'pos'])}\n",
      "\n",
      "Example 1:\n",
      "Text: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "Label: 1 (0=negative, 1=positive)\n",
      "\n",
      "Example 2:\n",
      "Text: the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "Label: 1 (0=negative, 1=positive)\n",
      "\n",
      "Example 3:\n",
      "Text: effective but too-tepid biopic\n",
      "Label: 1 (0=negative, 1=positive)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm as notebook_tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# Load the Rotten Tomatoes dataset from the Hugging Face Hub\n",
    "ds = load_dataset(\"cornell-movie-review-data/rotten_tomatoes\")\n",
    "for split in ds:\n",
    "    print(f\"Split '{split}' contains {len(ds[split])} examples\")\n",
    "\n",
    "# Visualize the structure of the dataset\n",
    "print(\"\\nData structure:\")\n",
    "print(ds[\"train\"].features)\n",
    "\n",
    "for i in range(3):\n",
    "    example = ds[\"train\"][i]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Text: {example['text']}\")\n",
    "    print(f\"Label: {example['label']} (0=negative, 1=positive)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f50a0-0af4-4bdd-9a60-bab26f126c14",
   "metadata": {},
   "source": [
    "#### Exercise 1.2: A Pre-trained BERT and Tokenizer\n",
    "\n",
    "The model we will use is a *very* small BERT transformer called [Distilbert](https://huggingface.co/distilbert/distilbert-base-uncased) this model was trained (using self-supervised learning) on the same corpus as BERT but using the full BERT base model as a *teacher*.\n",
    "\n",
    "**Your next task**: Load the Distilbert model and corresponding tokenizer. Use the tokenizer on a few samples from the dataset and pass the tokens through the model to see what outputs are provided. I suggest you use the [`AutoModel`](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html) class (and the `from_pretrained()` method) to load the model and `AutoTokenizer` to load the tokenizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eefc651-8551-44c2-8340-37d64660fc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized inputs:\n",
      "{'input_ids': tensor([[  101,  1996,  2600,  2003, 16036,  2000,  2022,  1996,  7398,  2301,\n",
      "          1005,  1055,  2047,  1000, 16608,  1000,  1998,  2008,  2002,  1005,\n",
      "          1055,  2183,  2000,  2191,  1037, 17624,  2130,  3618,  2084,  7779,\n",
      "         29058,  8625, 13327,  1010,  3744,  1011, 18856, 19513,  3158,  5477,\n",
      "          4168,  2030,  7112, 16562,  2140,  1012,   102,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1996,  9882,  2135,  9603, 13633,  1997,  1000,  1996,  2935,\n",
      "          1997,  1996,  7635,  1000, 11544,  2003,  2061,  4121,  2008,  1037,\n",
      "          5930,  1997,  2616,  3685, 23613,  6235,  2522,  1011,  3213,  1013,\n",
      "          2472,  2848,  4027,  1005,  1055,  4423,  4432,  1997,  1046,  1012,\n",
      "          1054,  1012,  1054,  1012, 23602,  1005,  1055,  2690,  1011,  3011,\n",
      "          1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "\n",
      "Model outputs:\n",
      "BaseModelOutput(last_hidden_state=tensor([[[-0.0332, -0.0168,  0.0194,  ...,  0.0476,  0.5834,  0.3036],\n",
      "         [-0.0235, -0.0555, -0.3638,  ...,  0.1877,  0.5781, -0.1577],\n",
      "         [-0.0516, -0.1014, -0.1511,  ...,  0.1503,  0.2649, -0.1575],\n",
      "         ...,\n",
      "         [ 0.3688, -0.1147,  0.8428,  ..., -0.0708, -0.0178, -0.2516],\n",
      "         [ 0.0654, -0.0206,  0.1889,  ...,  0.1159,  0.2323, -0.2404],\n",
      "         [ 0.0373, -0.0104,  0.1203,  ...,  0.1049,  0.2852, -0.3035]],\n",
      "\n",
      "        [[-0.2062, -0.0490, -0.4036,  ..., -0.1186,  0.6141,  0.3919],\n",
      "         [-0.4361, -0.1647, -0.3533,  ...,  0.1086,  0.9478, -0.0272],\n",
      "         [-0.1164,  0.1690,  0.2698,  ..., -0.1971,  0.4372,  0.2527],\n",
      "         ...,\n",
      "         [-0.2341,  0.4810, -0.2634,  ..., -0.3397,  0.2567,  0.1274],\n",
      "         [ 0.7139,  0.0574, -0.3260,  ...,  0.2041, -0.3800, -0.3343],\n",
      "         [ 0.5649,  0.2806, -0.0295,  ...,  0.1297, -0.3160, -0.1874]]]), hidden_states=None, attentions=None)\n",
      "\n",
      "Last hidden state shape: torch.Size([2, 52, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize a batch of texts\n",
    "texts = [ds[\"train\"][0][\"text\"], ds[\"train\"][1][\"text\"]] # Fist two examples from the training set\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(\"\\nTokenized inputs:\")\n",
    "print(inputs)\n",
    "\n",
    "with torch.no_grad():  # no gradient calculation needed\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Inspect the model outputs\n",
    "print(\"\\nModel outputs:\")\n",
    "print(outputs)\n",
    "print(\"\\nLast hidden state shape:\", outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f6fd4-b80b-466d-b4ff-9aac0492c062",
   "metadata": {},
   "source": [
    "#### Exercise 1.3: A Stable Baseline\n",
    "\n",
    "In this exercise I want you to:\n",
    "1. Use Distilbert as a *feature extractor* to extract representations of the text strings from the dataset splits;\n",
    "2. Train a classifier (your choice, by an SVM from Scikit-learn is an easy choice).\n",
    "3. Evaluate performance on the validation and test splits.\n",
    "\n",
    "These results are our *stable baseline* -- the **starting** point on which we will (hopefully) improve in the next exercise.\n",
    "\n",
    "**Hint**: There are a number of ways to implement the feature extractor, but probably the best is to use a [feature extraction `pipeline`](https://huggingface.co/tasks/feature-extraction). You will need to interpret the output of the pipeline and extract only the `[CLS]` token from the *last* transformer layer. *How can you figure out which output that is?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(texts, batch_size=32):\n",
    "    \"\"\"Extract features from a list of texts using a pre-trained transformer model.\n",
    "     Args:\n",
    "         texts (list of str): List of input texts.\n",
    "         batch_size (int): Number of texts to process in each batch.\n",
    "     \n",
    "     Returns:\n",
    "         np.ndarray: Array of extracted features.\n",
    "     \"\"\"\n",
    "    \n",
    "    feature_extractor = pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer)\n",
    "    all_features = []\n",
    "    \n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        # estract texts for the current batch\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        # Extract features for the current batch\n",
    "        outputs = feature_extractor(batch_texts)\n",
    "        # Extract the CLS token features (first token) from each output\n",
    "        batch_features = [np.array(output)[0, 0] for output in outputs]\n",
    "        all_features.extend(batch_features)\n",
    "    \n",
    "    return np.array(all_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train features shape: (8530, 768)\n",
      "Train labels length: 8530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation features shape: (1066, 768)\n",
      "Validation labels length: 1066\n",
      "\n",
      "Test features shape: (1066, 768)\n",
      "Test labels length: 1066\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels for each split\n",
    "train_features = extract_features(ds['train']['text'])\n",
    "train_labels = ds['train']['label']\n",
    "print(\"\\nTrain features shape:\", train_features.shape)\n",
    "print(\"Train labels length:\", len(train_labels))\n",
    "\n",
    "val_features = extract_features(ds['validation']['text'])\n",
    "val_labels = ds['validation']['label']\n",
    "print(\"\\nValidation features shape:\", val_features.shape)\n",
    "print(\"Validation labels length:\", len(val_labels))\n",
    "\n",
    "test_features = extract_features(ds['test']['text'])\n",
    "test_labels = ds['test']['label']\n",
    "print(\"\\nTest features shape:\", test_features.shape)\n",
    "print(\"Test labels length:\", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b4ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LinearSVC...\n",
      "\n",
      "Evaluating on validation set...\n",
      "Validation Accuracy: 0.8218\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.7983\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       533\n",
      "           1       0.81      0.78      0.80       533\n",
      "\n",
      "    accuracy                           0.80      1066\n",
      "   macro avg       0.80      0.80      0.80      1066\n",
      "weighted avg       0.80      0.80      0.80      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import  LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load a LinearSVC classifier and train it on the extracted features\n",
    "print(\"\\nTraining LinearSVC...\")\n",
    "classifier = LinearSVC(max_iter=10000, random_state=42)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate the classifier on the validation and test sets\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "val_pred = classifier.predict(val_features)\n",
    "val_accuracy = accuracy_score(val_labels, val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Test the classifier on the test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_pred = classifier.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37141d1b-935b-425c-804c-b9b487853791",
   "metadata": {},
   "source": [
    "-----\n",
    "### Exercise 2: Fine-tuning Distilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a53f64-0238-42f2-bc20-86e51c77d2e5",
   "metadata": {},
   "source": [
    "In this exercise we will fine-tune the Distilbert model to (hopefully) improve sentiment analysis performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392b1ed-597b-4a92-90fc-10eb11eac515",
   "metadata": {},
   "source": [
    "#### Exercise 2.1: Token Preprocessing\n",
    "\n",
    "The first thing we need to do is *tokenize* our dataset splits. Our current datasets return a dictionary with *strings*, but we want *input token ids* (i.e. the output of the tokenizer). This is easy enough to do my hand, but the HugginFace `Dataset` class provides convenient, efficient, and *lazy* methods. See the documentation for [`Dataset.map`](https://huggingface.co/docs/datasets/v3.5.0/en/package_reference/main_classes#datasets.Dataset.map).\n",
    "\n",
    "**Tip**: Verify that your new datasets are returning for every element: `text`, `label`, `intput_ids`, and `attention_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e2a95-5b08-4f81-b824-59a0fb3404e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function for dataset mapping\n",
    "def tokenize(example):\n",
    "    \"\"\" Tokenize a single example from the dataset.\n",
    "        Args: example (dict): A single example from the dataset containing a \"text\" field.\n",
    "        Returns: dict: Tokenized representation of the input text.\n",
    "        \"\"\"\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512, return_tensors=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e592c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['text', 'label', 'input_ids', 'attention_mask']\n",
      "example: dict_keys(['text', 'label', 'input_ids', 'attention_mask']) \n",
      "example text: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "example label: 1\n",
      "example tokenized: [101, 1996, 2600, 2003, 16036, 2000, 2022, 1996, 7398, 2301, 1005, 1055, 2047, 1000, 16608, 1000, 1998, 2008, 2002, 1005, 1055, 2183, 2000, 2191, 1037, 17624, 2130, 3618, 2084, 7779, 29058, 8625, 13327, 1010, 3744, 1011, 18856, 19513, 3158, 5477, 4168, 2030, 7112, 16562, 2140, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "example attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Apply the tokenization function to the entire dataset using map\n",
    "ds = ds.map(tokenize, batched=True, num_proc=4)\n",
    "print(f\"Columns: {ds['train'].column_names}\")\n",
    "print(f\"example: {ds['train'][0].keys()} \")\n",
    "print(f\"example text: {ds['train'][0]['text']}\")\n",
    "print(f\"example label: {ds['train'][0]['label']}\")\n",
    "print(f\"example tokenized: {ds['train'][0]['input_ids']}\")\n",
    "print(f\"example attention mask: {ds['train'][0]['attention_mask']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a80de2-83c9-4c12-af4e-34babe23ffd1",
   "metadata": {},
   "source": [
    "#### Exercise 2.2: Setting up the Model to be Fine-tuned\n",
    "\n",
    "In this exercise we need to prepare the base Distilbert model for fine-tuning for a *sequence classification task*. This means, at the very least, appending a new, randomly-initialized classification head connected to the `[CLS]` token of the last transformer layer. Luckily, HuggingFace already provides an `AutoModel` for just this type of instantiation: [`AutoModelForSequenceClassification`](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodelforsequenceclassification). You will want you instantiate one of these for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6327d73-3b71-478a-9932-bb062a650c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Use AutoModelForSequenceClassification to load a new classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label={0: \"negative\", 1: \"positive\"}, label2id={\"negative\": 0, \"positive\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109f7bd-955f-4fc4-bc3e-75bd99a17adf",
   "metadata": {},
   "source": [
    "#### Exercise 2.3: Fine-tuning Distilbert\n",
    "\n",
    "Finally. In this exercise you should use a HuggingFace [`Trainer`](https://huggingface.co/docs/transformers/main/en/trainer) to fine-tune your model on the Rotten Tomatoes training split. Setting up the trainer will involve (at least):\n",
    "\n",
    "\n",
    "1. Instantiating a [`DataCollatorWithPadding`](https://huggingface.co/docs/transformers/en/main_classes/data_collator) object which is what *actually* does your batch construction (by padding all sequences to the same length).\n",
    "2. Writing an *evaluation function* that will measure the classification accuracy. This function takes a single argument which is a tuple containing `(logits, labels)` which you should use to compute classification accuracy (and maybe other metrics like F1 score, precision, recall) and return a `dict` with these metrics.  \n",
    "3. Instantiating a [`TrainingArguments`](https://huggingface.co/docs/transformers/v4.51.1/en/main_classes/trainer#transformers.TrainingArguments) object using some reasonable defaults.\n",
    "4. Instantiating a `Trainer` object using your train and validation splits, you data collator, and function to compute performance metrics.\n",
    "5. Calling `trainer.train()`, waiting, waiting some more, and then calling `trainer.evaluate()` to see how it did.\n",
    "\n",
    "**Tip**: When prototyping this laboratory I discovered the HuggingFace [Evaluate library](https://huggingface.co/docs/evaluate/en/index) which provides evaluation metrics. However I found it to have insufferable layers of abstraction and getting actual metrics computed. I suggest just using the Scikit-learn metrics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate(eval_predictions):\n",
    "    \"\"\" Compute evaluation metrics.\n",
    "        Args:\n",
    "            eval_predictions (tuple): A tuple containing logits and true labels.\n",
    "        Returns:\n",
    "            dict: A dictionary with accuracy, precision, recall, and F1 score.\n",
    "        \"\"\"\n",
    "    logits, labels = eval_predictions\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4d71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, output_dir: Optional[str] = None, overwrite_output_dir: bool = False, do_train: bool = False, do_eval: bool = False, do_predict: bool = False, eval_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'no', prediction_loss_only: bool = False, per_device_train_batch_size: int = 8, per_device_eval_batch_size: int = 8, per_gpu_train_batch_size: Optional[int] = None, per_gpu_eval_batch_size: Optional[int] = None, gradient_accumulation_steps: int = 1, eval_accumulation_steps: Optional[int] = None, eval_delay: Optional[float] = 0, torch_empty_cache_steps: Optional[int] = None, learning_rate: float = 5e-05, weight_decay: float = 0.0, adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-08, max_grad_norm: float = 1.0, num_train_epochs: float = 3.0, max_steps: int = -1, lr_scheduler_type: Union[transformers.trainer_utils.SchedulerType, str] = 'linear', lr_scheduler_kwargs: Union[dict[str, Any], str, NoneType] = <factory>, warmup_ratio: float = 0.0, warmup_steps: int = 0, log_level: str = 'passive', log_level_replica: str = 'warning', log_on_each_node: bool = True, logging_dir: Optional[str] = None, logging_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'steps', logging_first_step: bool = False, logging_steps: float = 500, logging_nan_inf_filter: bool = True, save_strategy: Union[transformers.trainer_utils.SaveStrategy, str] = 'steps', save_steps: float = 500, save_total_limit: Optional[int] = None, save_safetensors: Optional[bool] = True, save_on_each_node: bool = False, save_only_model: bool = False, restore_callback_states_from_checkpoint: bool = False, no_cuda: bool = False, use_cpu: bool = False, use_mps_device: bool = False, seed: int = 42, data_seed: Optional[int] = None, jit_mode_eval: bool = False, use_ipex: bool = False, bf16: bool = False, fp16: bool = False, fp16_opt_level: str = 'O1', half_precision_backend: str = 'auto', bf16_full_eval: bool = False, fp16_full_eval: bool = False, tf32: Optional[bool] = None, local_rank: int = -1, ddp_backend: Optional[str] = None, tpu_num_cores: Optional[int] = None, tpu_metrics_debug: bool = False, debug: Union[str, list[transformers.debug_utils.DebugOption]] = '', dataloader_drop_last: bool = False, eval_steps: Optional[float] = None, dataloader_num_workers: int = 0, dataloader_prefetch_factor: Optional[int] = None, past_index: int = -1, run_name: Optional[str] = None, disable_tqdm: Optional[bool] = None, remove_unused_columns: Optional[bool] = True, label_names: Optional[list[str]] = None, load_best_model_at_end: Optional[bool] = False, metric_for_best_model: Optional[str] = None, greater_is_better: Optional[bool] = None, ignore_data_skip: bool = False, fsdp: Union[list[transformers.trainer_utils.FSDPOption], str, NoneType] = '', fsdp_min_num_params: int = 0, fsdp_config: Union[dict[str, Any], str, NoneType] = None, fsdp_transformer_layer_cls_to_wrap: Optional[str] = None, accelerator_config: Union[dict, str, NoneType] = None, deepspeed: Union[dict, str, NoneType] = None, label_smoothing_factor: float = 0.0, optim: Union[transformers.training_args.OptimizerNames, str] = 'adamw_torch', optim_args: Optional[str] = None, adafactor: bool = False, group_by_length: bool = False, length_column_name: Optional[str] = 'length', report_to: Union[NoneType, str, list[str]] = None, ddp_find_unused_parameters: Optional[bool] = None, ddp_bucket_cap_mb: Optional[int] = None, ddp_broadcast_buffers: Optional[bool] = None, dataloader_pin_memory: bool = True, dataloader_persistent_workers: bool = False, skip_memory_metrics: bool = True, use_legacy_prediction_loop: bool = False, push_to_hub: bool = False, resume_from_checkpoint: Optional[str] = None, hub_model_id: Optional[str] = None, hub_strategy: Union[transformers.trainer_utils.HubStrategy, str] = 'every_save', hub_token: Optional[str] = None, hub_private_repo: Optional[bool] = None, hub_always_push: bool = False, hub_revision: Optional[str] = None, gradient_checkpointing: bool = False, gradient_checkpointing_kwargs: Union[dict[str, Any], str, NoneType] = None, include_inputs_for_metrics: bool = False, include_for_metrics: list[str] = <factory>, eval_do_concat_batches: bool = True, fp16_backend: str = 'auto', push_to_hub_model_id: Optional[str] = None, push_to_hub_organization: Optional[str] = None, push_to_hub_token: Optional[str] = None, mp_parameters: str = '', auto_find_batch_size: bool = False, full_determinism: bool = False, torchdynamo: Optional[str] = None, ray_scope: Optional[str] = 'last', ddp_timeout: int = 1800, torch_compile: bool = False, torch_compile_backend: Optional[str] = None, torch_compile_mode: Optional[str] = None, include_tokens_per_second: Optional[bool] = False, include_num_input_tokens_seen: Optional[bool] = False, neftune_noise_alpha: Optional[float] = None, optim_target_modules: Union[NoneType, str, list[str]] = None, batch_eval_metrics: bool = False, eval_on_start: bool = False, use_liger_kernel: Optional[bool] = False, liger_kernel_config: Optional[dict[str, bool]] = None, eval_use_gather_object: Optional[bool] = False, average_tokens_across_devices: Optional[bool] = True) -> None\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Inspect the signature of TrainingArguments to understand its parameters\n",
    "print(inspect.signature(TrainingArguments.__init__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab17178d-5028-47e3-af97-953e8de5aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4572/300971899.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melena-daveri00\u001b[0m (\u001b[33melena-daveri00-universit-di-firenze\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/eledaveri/DLA/Labs/DLALabs/wandb/run-20250830_204534-2k0nalex</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elena-daveri00-universit-di-firenze/huggingface/runs/2k0nalex' target=\"_blank\">distilbert-rotten-tomatoes-run</a></strong> to <a href='https://wandb.ai/elena-daveri00-universit-di-firenze/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elena-daveri00-universit-di-firenze/huggingface' target=\"_blank\">https://wandb.ai/elena-daveri00-universit-di-firenze/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elena-daveri00-universit-di-firenze/huggingface/runs/2k0nalex' target=\"_blank\">https://wandb.ai/elena-daveri00-universit-di-firenze/huggingface/runs/2k0nalex</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1602' max='1602' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1602/1602 2:22:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.309400</td>\n",
       "      <td>0.353392</td>\n",
       "      <td>0.850844</td>\n",
       "      <td>0.859167</td>\n",
       "      <td>0.813758</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>0.389317</td>\n",
       "      <td>0.843340</td>\n",
       "      <td>0.846929</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.866792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.479846</td>\n",
       "      <td>0.848030</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.839122</td>\n",
       "      <td>0.861163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./Distilbert_rotten_tomatoes_tokenizer/tokenizer_config.json',\n",
       " './Distilbert_rotten_tomatoes_tokenizer/special_tokens_map.json',\n",
       " './Distilbert_rotten_tomatoes_tokenizer/vocab.txt',\n",
       " './Distilbert_rotten_tomatoes_tokenizer/added_tokens.json',\n",
       " './Distilbert_rotten_tomatoes_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "# load a data collator that will dynamically pad the inputs received\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./Distilbert_results\",\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"distilbert-rotten-tomatoes-run\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,  \n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    fp16=True,  # Use mixed precision\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    load_best_model_at_end=True)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=evaluate\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "trainer.save_model(\"./Distilbert_rotten_tomatoes_model\")\n",
    "tokenizer.save_pretrained(\"./Distilbert_rotten_tomatoes_tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9069802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 01:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3902638852596283,\n",
       " 'eval_accuracy': 0.8330206378986866,\n",
       " 'eval_f1': 0.842756183745583,\n",
       " 'eval_precision': 0.7963272120200334,\n",
       " 'eval_recall': 0.8949343339587242,\n",
       " 'eval_runtime': 92.8216,\n",
       " 'eval_samples_per_second': 11.484,\n",
       " 'eval_steps_per_second': 0.366,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8376de-8554-4a13-aac3-59257f3eb3fd",
   "metadata": {},
   "source": [
    "-----\n",
    "### Exercise 3: Choose at Least One\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55cf4d-e64b-47fc-b8d5-37288b72d90d",
   "metadata": {},
   "source": [
    "#### Exercise 3.1: Efficient Fine-tuning for Sentiment Analysis (easy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f183856-1111-4fe9-81f1-691fe7c1b706",
   "metadata": {},
   "source": [
    "In Exercise 2 we fine-tuned the *entire* Distilbert model on Rotten Tomatoes. This is expensive, even for a small model. Find an *efficient* way to fine-tune Distilbert on the Rotten Tomatoes dataset (or some other dataset).\n",
    "\n",
    "**Hint**: You could check out the [HuggingFace PEFT library](https://huggingface.co/docs/peft/en/index) for some state-of-the-art approaches that should \"just work\". How else might you go about making fine-tuning more efficient without having to change your training pipeline from above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6bca5-9b36-424e-898c-52c0777eae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,042 || all params: 67,842,052 || trainable%: 1.3075\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import numpy as np\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# Define LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                      # low rank (4-16)\n",
    "    lora_alpha=32,            # scaling\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"],  # LoRA target modules for DistilBERT\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",              # \"none\"|\"all\"|\"lora_only\"\n",
    "    task_type=\"SEQ_CLS\"       # sequene classification\n",
    ")\n",
    "\"\"\"\n",
    "q_lin: query projection layer\n",
    "k_lin: key projection layer\n",
    "v_lin: value projection layer\n",
    "out_lin: output projection layer\n",
    "\"\"\"\n",
    "# get the PEFT model --> apply LoRA to the pre-trained model\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilbert-peft\",\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"distilbert-rotten-tomatoes-peft-run\",\n",
    "    eval_strategy=\"epoch\",      \n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,         # With LoRA we use a higher lr (es. 1e-4 - 5e-4)\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True        \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec16d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4572/3247528465.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1602' max='1602' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1602/1602 1:25:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.205500</td>\n",
       "      <td>0.358162</td>\n",
       "      <td>0.861163</td>\n",
       "      <td>0.864220</td>\n",
       "      <td>0.845601</td>\n",
       "      <td>0.883677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.395202</td>\n",
       "      <td>0.852720</td>\n",
       "      <td>0.851185</td>\n",
       "      <td>0.860153</td>\n",
       "      <td>0.842402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172600</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.855535</td>\n",
       "      <td>0.856075</td>\n",
       "      <td>0.852886</td>\n",
       "      <td>0.859287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 01:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.43398192524909973,\n",
       " 'eval_accuracy': 0.8339587242026266,\n",
       " 'eval_f1': 0.8371665133394665,\n",
       " 'eval_precision': 0.8212996389891697,\n",
       " 'eval_recall': 0.8536585365853658,\n",
       " 'eval_runtime': 92.9287,\n",
       " 'eval_samples_per_second': 11.471,\n",
       " 'eval_steps_per_second': 0.366,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=evaluate\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./Distilbert_rotten_tomatoes_peft_model\")\n",
    "tokenizer.save_pretrained(\"./Distilbert_rotten_tomatoes_peft_tokenizer\")\n",
    "trainer.evaluate(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24743ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'train' contains 45615 examples\n",
      "Split 'test' contains 12284 examples\n",
      "Split 'validation' contains 2000 examples\n",
      "\n",
      "Data structure:\n",
      "{'text': Value('string'), 'label': ClassLabel(names=['negative', 'neutral', 'positive'])}\n",
      "\n",
      "Example 1:\n",
      "Text: \"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"\n",
      "Label: 2 (0=negative, 1=neutral, 2=positive)\n",
      "\n",
      "Example 2:\n",
      "Text: \"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\"\n",
      "Label: 1 (0=negative, 1=neutral, 2=positive)\n",
      "\n",
      "Example 3:\n",
      "Text: Sorry bout the stream last night I crashed out but will be on tonight for sure. Then back to Minecraft in pc tomorrow night.\n",
      "Label: 1 (0=negative, 1=neutral, 2=positive)\n",
      "Columns: ['text', 'label', 'input_ids', 'attention_mask']\n",
      "example: dict_keys(['text', 'label', 'input_ids', 'attention_mask']) \n",
      "example text: \"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"\n",
      "example label: 2\n",
      "example tokenized: [101, 1000, 1053, 2102, 1030, 5310, 1999, 1996, 2434, 4433, 1997, 1996, 5504, 2338, 1010, 2128, 7606, 11320, 8091, 5175, 1996, 2645, 1997, 27589, 18367, 2015, 1012, 1001, 3407, 17706, 2705, 10259, 28578, 2271, 7630, 8091, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "example attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Twitter Sentiment Analysis dataset from the Hugging Face Hub\n",
    "# Same as before but with 3 labels (negative, neutral, positive) and a bigger dataset\n",
    "ds_twitter = load_dataset(\"tweet_eval\", \"sentiment\")\n",
    "for split in ds_twitter:\n",
    "    print(f\"Split '{split}' contains {len(ds_twitter[split])} examples\")\n",
    "\n",
    "print(\"\\nData structure:\")\n",
    "print(ds_twitter[\"train\"].features)\n",
    "\n",
    "for i in range(3):\n",
    "    example = ds_twitter[\"train\"][i]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Text: {example['text']}\")\n",
    "    print(f\"Label: {example['label']} (0=negative, 1=neutral, 2=positive)\") # 3 label\n",
    "\n",
    "# Aplly the tokenization function to the entire dataset using map\n",
    "ds_twitter = ds_twitter.map(tokenize, batched=True, num_proc=4)\n",
    "print(f\"Columns: {ds_twitter['train'].column_names}\")\n",
    "print(f\"example: {ds_twitter['train'][0].keys()} \")\n",
    "print(f\"example text: {ds_twitter['train'][0]['text']}\")\n",
    "print(f\"example label: {ds_twitter['train'][0]['label']}\")\n",
    "print(f\"example tokenized: {ds_twitter['train'][0]['input_ids']}\")\n",
    "print(f\"example attention mask: {ds_twitter['train'][0]['attention_mask']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb00c19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_4572/3180297425.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,811 || all params: 67,843,590 || trainable%: 1.3086\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8553' max='8553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8553/8553 7:18:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.656143</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.689136</td>\n",
       "      <td>0.725259</td>\n",
       "      <td>0.674762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.634364</td>\n",
       "      <td>0.724500</td>\n",
       "      <td>0.694394</td>\n",
       "      <td>0.721402</td>\n",
       "      <td>0.679254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.627691</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.713712</td>\n",
       "      <td>0.712907</td>\n",
       "      <td>0.714563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 17:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6897343993186951,\n",
       " 'eval_accuracy': 0.6872354281992836,\n",
       " 'eval_f1': 0.6853383354151851,\n",
       " 'eval_precision': 0.6778643904462941,\n",
       " 'eval_recall': 0.6953055425995139,\n",
       " 'eval_runtime': 1066.0211,\n",
       " 'eval_samples_per_second': 11.523,\n",
       " 'eval_steps_per_second': 0.36,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load the pre-trained model and aplly the new classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=3,  # for Twitter sentiment: 0=negative, 1=neutral, 2=positive\n",
    "    id2label={0: \"negative\", 1: \"neutral\", 2: \"positive\"},\n",
    "    label2id={\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    ")\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "\n",
    "def evaluate_multiclass(eval_predictions):\n",
    "    logits, labels = eval_predictions\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Use 'macro' average for multi-class classification\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='macro')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Same training arguments as before\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_twitter[\"train\"],\n",
    "    eval_dataset=ds_twitter[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=evaluate_multiclass\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./Distilbert_tweet_eval_peft_model\")\n",
    "tokenizer.save_pretrained(\"./Distilbert_tweet_eval_peft_tokenizer\")\n",
    "trainer.evaluate(ds_twitter[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25259738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 18:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7098513245582581,\n",
       " 'eval_accuracy': 0.6803972647346141,\n",
       " 'eval_f1': 0.6716565079575956,\n",
       " 'eval_precision': 0.6818705188599271,\n",
       " 'eval_recall': 0.6748206667169643,\n",
       " 'eval_runtime': 1084.6351,\n",
       " 'eval_samples_per_second': 11.325,\n",
       " 'eval_steps_per_second': 0.354,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ds_twitter[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeca737-ee00-4d98-a3ae-f4d6eb3d264f",
   "metadata": {},
   "source": [
    "#### Exercise 3.2: Fine-tuning a CLIP Model (harder)\n",
    "\n",
    "Use a (small) CLIP model like [`openai/clip-vit-base-patch16`](https://huggingface.co/openai/clip-vit-base-patch16) and evaluate its zero-shot performance on a small image classification dataset like ImageNette or TinyImageNet. Fine-tune (using a parameter-efficient method!) the CLIP model to see how much improvement you can squeeze out of it.\n",
    "\n",
    "**Note**: There are several ways to adapt the CLIP model; you could fine-tune the image encoder, the text encoder, or both. Or, you could experiment with prompt learning.\n",
    "\n",
    "**Tip**: CLIP probably already works very well on ImageNet and ImageNet-like images. For extra fun, look for an image classification dataset with different image types (e.g. *sketches*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b59ec2-4fe6-44c6-ab0b-0069f486bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42ed48-444d-47d4-bd8b-839a99e7996a",
   "metadata": {},
   "source": [
    "#### Exercise 3.3: Choose your Own Adventure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f9129-ef2e-45f7-9e8f-baa697ccd91e",
   "metadata": {},
   "source": [
    "There are a *ton* of interesting and fun models on the HuggingFace hub. Pick one that does something interesting and adapt it in some way to a new task. Or, combine two or more models into something more interesting or fun. The sky's the limit.\n",
    "\n",
    "**Note**: Reach out to me by email or on the Discord if you are unsure about anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c150bd36-6535-4724-a06d-a61632d3132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
